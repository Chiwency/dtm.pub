# 缓存一致性

## 概述
在实际的项目中，当 QPS 变高，通常会引入 Redis 缓存来缓解数据库的查询压力。但是一旦引入了缓存，那么一个数据在 Redis 和数据库两处进行了存储，就会有数据一致性的问题。 DTM 致力于解决数据一致性问题，在分析了行业的现有做法后，提出了新架构方案，本文将详细叙述

## 强一致方案
当业务访问量不大时，我们可以在服务中，直接访问数据库，这样的解决方案简单直接，没有问题。

当业务量增大时，数据库很容易成为瓶颈，此时最便捷的解决办法是，升级数据库配置，让数据库直接提供更高的 qps 来应对业务增长。此方法优点是，不需要任何开发工作，升级配置就可以支撑更高的业务量，但是有以下缺点：
- 单机数据库配置有上限，磁盘的 IOPS ，单机内存，单机 CPU 都有上限，到了一定程度，无法再往上升级
- 配置升级很昂贵，这些配置的升级一倍，需要的成本可能是4倍，甚至10倍，这种方案硬件成本上升过快，难以应对大用户量的应用

**开发影响：** 这种方案，应用不需要任何修改，完全不需要修改。
## 弱一致数据库方案
上述升级配置的方式，对开发人员非常友好，但是成本过于昂贵，缺点非常明显，那么有没有办法做横向扩展，让成本只是线性上升呢？

绝大多数的互联网应用都是读多写少的应用，采用数据库的主从复制，进行读写分离，可以比较好的应对用户量上涨带来的问题，对比上述升级配置的方案，主从分离具备一下特点
- 随着用户增长，可以通过增加更多的从库，分担数据库的访问压力，这个成本是线性增加，不是指数增加，比前面的垂直升级配置方案更好
- 理论上一个主库可以增加大量的从库，这种扩展的上限比前面垂直升级方案上限要高很多

但是这里的方案，已经是弱一致性，数据从主库到从库，需要一定的时间。应用在主库上写完之后，立即去从库读，可能读取不到最新数据，因此这个时候是弱一致性。

**开发影响：** 在这种弱一致性方案下，开发就需要针对应用做修改，开发需要区分出一致性要求强的读请求，和一致性要求低的读请求，将强一致的调度到主库，弱一致的调度到从库。

## Redis 缓存方案
上述的数据库方案在每用户成本上，是很高的。在当今的互联网应用中，用户量非常大，纯数据库方案，会导致成本居高不下，此时其他技术方案会成为更佳的选择。

使用 Redis 将数据缓存在内存中，是当今非常通用的数据查询方案，对比上述的数据库方案， Redis 方案具备以下特点：
- 数据存储在内存，访问速度极快，单机 Redis 通常比单机数据库提供高达 10~100 倍的访问支持
- Redis 也支持主从复制，分片等，可以很轻松的提供应用所需要的 qps

在并发访问方面， Redis 完美的提供了支持，但是也带来了不少的问题：
- Redis 的存储形式是内存，与数据库的数据形式不一样，需要开发人员手动维护
- Redis 与数据库没有前面数据库主从的这种方式的自动数据同步，相关数据的一致性需要开发者手动维护

**开发影响：** 开发者需要手动维护跟数据库格式不同的缓存数据，另外还需要解决 Redis 缓存与数据库数据不一致的问题。

## 缓存更新为什么会会不一致
引入了 Redis 缓存之后，数据会同时存储在数据库和 Redis。一般业界会采用写完数据库后，删除/更新缓存数据的策略。由于保存到缓存和保存到数据库两个操作之间不是原子的，一定会有时间差，因此这两个数据之间会有一个不一致的时间窗口，通常这个窗口不大。但是两个中间可能发生宕机，也可能发生各种网络错误，因此就有可能发生完成了其中一个，但是未完成另一个，导致数据会出现较长时间不一致。

举一个场景来说明上述不一致的情况，数据用户将数据 A 修改为 B ，应用修改完数据库之后，再去修改缓存，如果未发生异常，那么数据库和缓存的数据都是 B，没有问题。但是分布式系统中，可能会发生进程crash、宕机等事件，因此如果更新完数据库，尚未更新缓存时，出现进程crash，那么数据库和缓存的数据就可能出现较长时间的不一致。

面对这里的较长时间不一致的情况，想要彻底解决，并不是一件容易的事，我们下面分各种应用情况来介绍解决方案。

## 方案一：较短的缓存时间
这个方案，是最简单的方案，适合并发量不大应用。如果应用的并发不高，那么整个缓存系统，只需要设置了一个较短的缓存时间，例如一分钟。这种情况下数据库需要承担的负载是：大约每一分钟，需要将访问到的缓存数据全部生成一遍，在并发量不大的情况下，这种策略是可行的。

上述这种策略非常简单，易于理解和实现，缓存系统提供的语义是，大多数情况下，缓存和数据库之间不一致的时间窗口是很短的，在较低概率发生进程crash的情况下，不一致的时间窗口会达到一分钟。

应用在上述约束下，需要将一致性要求不高的数据读取，从缓存读取；而将一致性要求较高的读，不走缓存，直接从数据库查询。

## 方案二：消息队列保证一致
假如应用的并发量很高，缓存过期时间需要比一分钟更长，而且应用中的大量请求不能够容忍较长时间的不一致，那么这个时候，可以通过使用消息队列的方式，来更新缓存。具体的做法是：
- 更新数据库时，同时将更新缓存的消息写入本地表，随着数据库更新操作的提交而提交。
- 写一个轮询任务，不断轮询这部分消息，发给消息队列。
- 消费消息队列中的消息，更新/删除缓存

这种做法可以保证数据库更新之后，缓存一定会被更新。但这种这种架构方案很重，这几个部分开发维护成本都不低：消息队列的维护；高效轮询任务的开发与维护。

## 方案三：订阅 binlog
这个方案适用场景与方案二非常类似，原理又与数据库的主从同步类似，数据库的主从同步是通过订阅binlog，将主库的更新应用到从库上，而这个方案则是通过订阅binlog，将数据库的更新应用到缓存上。具体做法是：
- 部署并配置阿里开源的 canal ，让它订阅数据库的binlog
- 通过 canal等工具 监听数据更新，同步更新/删除缓存

这种方案也可以保证数据库更新之后，缓存一定会被更新，但是这种架构方案跟前面的方案一样，也非常重。一方面 canal 的学习维护成本不低，另一方面，开发者可能只需要少量数据更新缓存，通过订阅所有的 binlog 来做这个事情，比较浪费。

## 方案四： dtm 二阶段消息方案
dtm 里的二阶段消息模式，非常适合这里的修改数据库之后更新/删除缓存，主要代码如下：

``` Go
msg := dtmcli.NewMsg(DtmServer, gid).
	Add(busi.Busi+"/UpdateRedis", &Req{Key: key1})
err := msg.DoAndSubmitDB(busi.Busi+"/QueryPrepared", db, func(tx *sql.Tx) error {
  // update db data with key1
})
```

这段代码，DoAndSubmitDB会进行本地数据库操作，进行数据库的数据修改，修改完成后，会提交一个二阶段消息事务，消息事务将会异步调用 UpdateRedis。假如本地事务执行之后，就立刻发生了进程 crash 事件，那么 dtm 会进行回查调用 QueryPrepared ，保证本地事务提交成功的情况下，UpdateRedis 会被最少成功执行一次。

回查的逻辑非常简单，只需要copy类似下面这样的代码即可：
``` Go
	app.GET(BusiAPI+"/QueryPreparedB", dtmutil.WrapHandler2(func(c *gin.Context) interface{} {
		return MustBarrierFromGin(c).QueryPrepared(dbGet())
	}))
```

这种方案的优点：
- 方案简单易用，代码简短易读
- dtm 本身是一个无状态的普通应用，依赖的存储引擎 redis/mysql 是常见的基础设施，不需要额外维护消息队列或者 canal
- 相关的操作模块化，易维护，不需要像消息队列或者 canal 在其他地方写消费者的逻辑

